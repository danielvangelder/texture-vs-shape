{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load pretrained model\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- pytorch\n",
    "- torchvision\n",
    "- numpy\n",
    "\n",
    "\n",
    "\n",
    "**Models to test:**\n",
    "\n",
    "- AlexNet\n",
    "- VGG-16\n",
    "- GoogLeNet\n",
    "- ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from probabilities_to_decision import ImageNetProbabilitiesTo16ClassesMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# alexnet \n",
    "# vgg_16 \n",
    "# googlenet \n",
    "# resnet_50 \n",
    "\n",
    "alexnet = models.alexnet(pretrained=True, progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load test files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMAGES = \"../stimuli/style-transfer-preprocessed-512/\"\n",
    "directories = [x for x in os.listdir(PATH_TO_IMAGES) if os.path.isdir(PATH_TO_IMAGES + x)]\n",
    "\n",
    "## Deprecated:\n",
    "## Each element in the `test_set` list will be a pair: `(true label, image url)`\n",
    "# test_set = []\n",
    "# for directory in directories:\n",
    "#     urls = [x for x in os.listdir(PATH_TO_IMAGES + directory) if \".png\" in x]\n",
    "#     for url in urls:\n",
    "#         abs_path = os.path.abspath(PATH_TO_IMAGES + directory + \"/\" + url)\n",
    "#         test_set.append((directory, abs_path))\n",
    "# print(\"Loaded test set of size:\", len(test_set))\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_set = datasets.ImageFolder(PATH_TO_IMAGES, transform=transform)\n",
    "test = DataLoader(test_set, batch_size=1, shuffle=False) # Load in batches of size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , url: ../stimuli/style-transfer-preprocessed-512/airplane\\airplane1-bicycle2.png\n",
      "tensor([[[[ 0.0741,  0.2282, -0.1486,  ...,  0.0741,  0.3138,  0.3309],\n",
      "          [ 0.1939,  0.0741,  0.1254,  ...,  0.4679,  0.6734,  0.1939],\n",
      "          [ 0.3994,  0.5193,  0.6221,  ...,  1.1529,  1.1529,  0.6221],\n",
      "          ...,\n",
      "          [ 0.7077,  1.1872,  1.3413,  ...,  0.8961,  1.0331,  0.8618],\n",
      "          [ 1.3413,  1.2557,  1.2385,  ...,  0.8618,  1.0159,  0.9646],\n",
      "          [ 1.1358,  1.1872,  1.2385,  ...,  0.8276,  0.9646,  0.9988]],\n",
      "\n",
      "         [[ 0.2227,  0.3452, -0.0749,  ...,  0.1001,  0.4503,  0.5203],\n",
      "          [ 0.3102,  0.1702,  0.2227,  ...,  0.5553,  0.8704,  0.3277],\n",
      "          [ 0.5553,  0.6954,  0.7829,  ...,  1.3606,  1.6232,  0.9755],\n",
      "          ...,\n",
      "          [ 0.7654,  1.2906,  1.4657,  ...,  0.9405,  1.0805,  0.9580],\n",
      "          [ 1.4132,  1.4482,  1.4132,  ...,  0.8880,  1.0455,  0.9930],\n",
      "          [ 1.2031,  1.2731,  1.3957,  ...,  0.8004,  1.0280,  0.9755]],\n",
      "\n",
      "         [[ 0.3568,  0.4962,  0.0256,  ...,  0.3742,  0.7054,  0.8099],\n",
      "          [ 0.4788,  0.3742,  0.3568,  ...,  0.8274,  1.1934,  0.6705],\n",
      "          [ 0.7402,  0.8622,  0.8797,  ...,  1.5245,  1.7860,  1.3851],\n",
      "          ...,\n",
      "          [ 0.9668,  1.5071,  1.6291,  ...,  0.8099,  1.1237,  1.0365],\n",
      "          [ 1.6117,  1.7163,  1.6291,  ...,  0.7402,  1.0017,  1.0539],\n",
      "          [ 1.4200,  1.5420,  1.6117,  ...,  0.7402,  0.9319,  1.0017]]]])\n"
     ]
    }
   ],
   "source": [
    "# Class that gi\n",
    "def predict_for_image(model, image_tensors):\n",
    "    # get softmax output\n",
    "    softmax_output = torch.softmax(model(image_tensors),1) # replace with your favourite CNN\n",
    "    # convert to numpy\n",
    "    softmax_output_numpy = softmax_output.detach().numpy().flatten() # replace with conversion\n",
    "    # create mapping\n",
    "    mapping = ImageNetProbabilitiesTo16ClassesMapping()\n",
    "    # obtain decision \n",
    "    decision_from_16_classes = mapping.probabilities_to_decision(softmax_output_numpy)\n",
    "    return decision_from_16_classes\n",
    "\n",
    "\n",
    "# Dictionary that stores class labels\n",
    "class_labels = {v: k for k, v in test_set.class_to_idx.items()}\n",
    "\n",
    "# Test run for first 100 images\n",
    "for i, data in enumerate(test):\n",
    "    print(i, ', url:', test_set.imgs[i][0])\n",
    "    images, labels = data\n",
    "    print(images)\n",
    "    break\n",
    "#     output = predict_for_image(alexnet, images)\n",
    "#     actual = class_labels[labels.item()]\n",
    "#     print('Predicted:', output,\", Actual:\", actual, '\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "input_image = Image.open(PATH_TO_IMAGES+\"airplane/airplane1-bicycle2.png\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "# print(torch.eq(images, input_batch))\n",
    "print(torch.all(images.eq(input_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
